Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja bis einschlie√ülich Epoche 50, dann nicht rangadaptiv 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.1 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.1149, 0.1865, 0.2431, 0.3716, 0.6476, 0.3891, 0.8643, 0.8773, 0.8805, 0.8808, 0.76, 0.8787, 0.8709, 0.9095, 0.9135, 0.9248, 0.9281, 0.932, 0.9367, 0.9411, 0.9429, 0.9277, 0.9389, 0.9354, 0.9447, 0.9487, 0.94, 0.9448, 0.9474, 0.947, 0.9454, 0.9505, 0.9495, 0.9517, 0.9569, 0.9536, 0.9404, 0.9603, 0.96, 0.9564, 0.9577, 0.9549, 0.9566, 0.9619, 0.9609, 0.8301, 0.7625, 0.9168, 0.9211, 0.9316, 0.9261, 0.9476, 0.9528, 0.9572, 0.9579, 0.9589, 0.9602, 0.963, 0.9613, 0.9639, 0.9668, 0.9668, 0.9663, 0.9666, 0.967, 0.9675, 0.9685, 0.9646, 0.9676, 0.968, 0.9685, 0.9705, 0.9689, 0.9705, 0.9671, 0.9706, 0.9688, 0.9646, 0.9696, 0.9702, 0.9687, 0.9704, 0.9717, 0.9711, 0.9683, 0.9718, 0.9694, 0.9708, 0.9712, 0.9693, 0.9702, 0.9698, 0.9716, 0.9711, 0.9724, 0.9716, 0.9722, 0.9722, 0.9719, 0.9726, 0.9722] 
Trainingsdauer: 893.3770740032196 
Rang Entwicklung Layer 1: [500, 98, 77, 71, 65, 60, 56, 54, 50, 47, 44, 39, 35, 33, 31, 30, 29, 28, 28, 27, 26, 26, 26, 25, 25, 23, 23, 23, 22, 22, 22, 21, 21, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20] 
Rang Entwicklung Layer 2: [500, 80, 74, 71, 67, 64, 62, 61, 59, 57, 55, 52, 50, 48, 47, 46, 45, 45, 44, 44, 43, 42, 42, 42, 41, 40, 39, 39, 39, 38, 38, 37, 37, 36, 36, 35, 35, 34, 34, 34, 34, 33, 33, 32, 32, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21] 
Rang Entwicklung Layer 3: [500, 79, 74, 72, 68, 64, 63, 61, 59, 58, 57, 54, 52, 51, 50, 49, 48, 47, 47, 46, 45, 45, 45, 44, 44, 43, 43, 43, 42, 42, 42, 41, 41, 40, 40, 40, 39, 39, 38, 38, 38, 37, 36, 36, 36, 29, 28, 27, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.2872934341430664, 1.9324829578399658, 1.4741352796554565, 0.8976404070854187, 2.2499167919158936, 0.4678720533847809, 0.48225948214530945, 0.4131550192832947, 0.440769761800766, 0.7060085535049438, 0.4050280749797821, 0.4652263820171356, 0.37444424629211426, 0.2628243565559387, 0.2288558930158615, 0.2369871586561203, 0.2473539412021637, 0.19313500821590424, 0.18944525718688965, 0.18092398345470428, 0.16802038252353668, 0.18893694877624512, 0.22441676259040833, 0.17466428875923157, 0.13517601788043976, 0.20776541531085968, 0.16805796325206757, 0.16606837511062622, 0.1465517282485962, 0.15359805524349213, 0.13909076154232025, 0.10518574714660645, 0.15129980444908142, 0.11339840292930603, 0.11966638267040253, 0.1866089552640915, 0.06303674727678299, 0.09557457268238068, 0.15140068531036377, 0.12564198672771454, 0.14110922813415527, 0.10083836317062378, 0.0628545954823494, 0.1688220053911209, 0.648274838924408, 0.5932166576385498, 0.29792091250419617, 0.32546088099479675, 0.20392969250679016, 0.2590995728969574, 0.15294113755226135, 0.19080893695354462, 0.11749377101659775, 0.12883953750133514, 0.07951857149600983, 0.09310004115104675, 0.0960364118218422, 0.09231381863355637, 0.06346012651920319, 0.05968448147177696, 0.0673004537820816, 0.04502935707569122, 0.06930641084909439, 0.05228637531399727, 0.0562349371612072, 0.046704430133104324, 0.04027119651436806, 0.03430364653468132, 0.03518569469451904, 0.03681918606162071, 0.030877411365509033, 0.04151250422000885, 0.06490707397460938, 0.06842619925737381, 0.021885212510824203, 0.052714958786964417, 0.05083540454506874, 0.046058449894189835, 0.04110926017165184, 0.021563855931162834, 0.029345355927944183, 0.03877563774585724, 0.029854005202651024, 0.03736919164657593, 0.027258597314357758, 0.024028489366173744, 0.026829572394490242, 0.026354346424341202, 0.04124096781015396, 0.02452380768954754, 0.030362974852323532, 0.03237516060471535, 0.01192397903650999, 0.021296923980116844, 0.02267569489777088, 0.01428722869604826, 0.04040512070059776, 0.01488326583057642, 0.016265874728560448, 0.025875752791762352] 
