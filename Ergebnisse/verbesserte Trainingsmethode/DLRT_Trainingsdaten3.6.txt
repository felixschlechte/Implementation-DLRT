Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja bis einschlie√ülich Epoche 50, dann nicht rangadaptiv 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.19 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.0928, 0.1135, 0.1135, 0.1135, 0.1135, 0.1144, 0.2342, 0.4352, 0.5778, 0.7184, 0.7847, 0.7919, 0.8606, 0.8811, 0.893, 0.8975, 0.8922, 0.8061, 0.8898, 0.901, 0.8939, 0.9104, 0.9113, 0.9108, 0.9151, 0.9185, 0.9183, 0.9226, 0.9247, 0.926, 0.9227, 0.9217, 0.9249, 0.9252, 0.9206, 0.922, 0.8734, 0.4743, 0.8983, 0.9027, 0.3561, 0.9009, 0.8935, 0.8371, 0.8598, 0.8945, 0.9007, 0.8952, 0.9065, 0.9102, 0.9097, 0.9156, 0.9187, 0.9217, 0.9235, 0.9263, 0.9241, 0.9252, 0.9274, 0.9265, 0.9288, 0.9276, 0.9277, 0.9282, 0.9294, 0.9311, 0.9313, 0.9337, 0.93, 0.9329, 0.9284, 0.9345, 0.9334, 0.9348, 0.9353, 0.9354, 0.9347, 0.9344, 0.9339, 0.9372, 0.9355, 0.9363, 0.9361, 0.9334, 0.9355, 0.9363, 0.9353, 0.9383, 0.9372, 0.9365, 0.9358, 0.939, 0.9389, 0.9396, 0.9371, 0.9377, 0.9377, 0.9385, 0.9347, 0.9398, 0.9369] 
Trainingsdauer: 806.7221083641052 
Rang Entwicklung Layer 1: [500, 25, 25, 25, 25, 25, 23, 19, 14, 10, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7] 
Rang Entwicklung Layer 2: [500, 24, 24, 24, 24, 24, 23, 20, 18, 15, 12, 8, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6] 
Rang Entwicklung Layer 3: [500, 24, 24, 24, 24, 24, 23, 20, 17, 15, 12, 9, 8, 7, 7, 7, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.2998886108398438, 2.3028011322021484, 2.29905104637146, 2.2957510948181152, 2.292417287826538, 1.9644553661346436, 1.6197410821914673, 1.2267951965332031, 0.754594087600708, 0.739790141582489, 0.6108419299125671, 0.4922080338001251, 0.42049750685691833, 0.356608510017395, 0.2925199568271637, 0.24888819456100464, 0.5710787773132324, 0.3807385265827179, 0.33425015211105347, 0.37470391392707825, 0.23505033552646637, 0.3007736802101135, 0.26810523867607117, 0.30977287888526917, 0.27940604090690613, 0.25655099749565125, 0.22953148186206818, 0.2012789398431778, 0.1808623969554901, 0.2674161493778229, 0.29717665910720825, 0.2238737940788269, 0.24362099170684814, 0.26405981183052063, 0.21227915585041046, 0.4406556785106659, 0.5838981866836548, 0.32352834939956665, 0.30410340428352356, 1.9205771684646606, 0.33716800808906555, 0.3274783194065094, 0.6138668060302734, 0.4136948585510254, 0.39551785588264465, 0.352996826171875, 0.33972683548927307, 0.2661333382129669, 0.3172305226325989, 0.2771826684474945, 0.3301999568939209, 0.23823130130767822, 0.245504230260849, 0.18903198838233948, 0.27307260036468506, 0.18290400505065918, 0.23823803663253784, 0.1851455420255661, 0.20512144267559052, 0.24167507886886597, 0.21525248885154724, 0.2573305368423462, 0.17071433365345, 0.13574974238872528, 0.1816781610250473, 0.187378391623497, 0.20677781105041504, 0.15081454813480377, 0.204694002866745, 0.22418169677257538, 0.18421593308448792, 0.1439770758152008, 0.15722255408763885, 0.20178580284118652, 0.16086545586585999, 0.15203969180583954, 0.17698365449905396, 0.14059098064899445, 0.17135055363178253, 0.18620894849300385, 0.13939213752746582, 0.13950638473033905, 0.1737099140882492, 0.10213463753461838, 0.1498655527830124, 0.1900770515203476, 0.1664058119058609, 0.15998348593711853, 0.12678466737270355, 0.14775113761425018, 0.13697347044944763, 0.12820057570934296, 0.11330550163984299, 0.23367474973201752, 0.15816079080104828, 0.14758238196372986, 0.10298021137714386, 0.13456928730010986, 0.1708592027425766, 0.1606433391571045] 
