Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja bis einschlie√ülich Epoche 50, dann nicht rangadaptiv 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.05 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.0507, 0.316, 0.4765, 0.6745, 0.7501, 0.8301, 0.8809, 0.8691, 0.8737, 0.8866, 0.9118, 0.9087, 0.9249, 0.9342, 0.9271, 0.9366, 0.9353, 0.9415, 0.9276, 0.9418, 0.9443, 0.9467, 0.9451, 0.9486, 0.9456, 0.9523, 0.9548, 0.9495, 0.9417, 0.9242, 0.8876, 0.9375, 0.9227, 0.9423, 0.9478, 0.936, 0.9173, 0.9472, 0.9502, 0.9471, 0.9436, 0.9527, 0.9521, 0.9562, 0.96, 0.9349, 0.9508, 0.9531, 0.951, 0.945, 0.9518, 0.9613, 0.9645, 0.9659, 0.9687, 0.9689, 0.9708, 0.9709, 0.9715, 0.9733, 0.9747, 0.9746, 0.9762, 0.9765, 0.9768, 0.976, 0.9766, 0.9752, 0.9755, 0.9757, 0.9778, 0.9766, 0.9773, 0.978, 0.9777, 0.9789, 0.9782, 0.9779, 0.9799, 0.9793, 0.9783, 0.9799, 0.9788, 0.9795, 0.979, 0.9795, 0.9789, 0.9793, 0.9793, 0.9789, 0.9793, 0.9792, 0.9798, 0.9792, 0.9792, 0.9792, 0.9802, 0.9797, 0.98, 0.98, 0.9802] 
Trainingsdauer: 1557.145967721939 
Rang Entwicklung Layer 1: [500, 254, 208, 198, 192, 185, 180, 178, 171, 168, 166, 164, 163, 162, 161, 159, 156, 155, 154, 152, 151, 148, 147, 147, 146, 145, 144, 143, 141, 141, 135, 133, 130, 130, 129, 125, 123, 121, 121, 121, 119, 118, 118, 117, 117, 116, 115, 115, 113, 113, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112] 
Rang Entwicklung Layer 2: [500, 207, 189, 183, 178, 174, 171, 170, 167, 166, 164, 163, 161, 161, 160, 159, 159, 157, 157, 156, 155, 155, 155, 154, 153, 152, 151, 151, 150, 150, 147, 145, 145, 144, 144, 143, 142, 141, 140, 139, 139, 138, 138, 138, 137, 137, 137, 137, 137, 136, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135] 
Rang Entwicklung Layer 3: [500, 207, 189, 184, 181, 176, 175, 174, 170, 170, 168, 167, 166, 165, 165, 164, 164, 163, 163, 162, 161, 161, 160, 160, 158, 158, 158, 157, 157, 157, 156, 154, 154, 154, 153, 153, 153, 152, 151, 151, 150, 149, 149, 148, 148, 148, 148, 148, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.2034242153167725, 1.4930055141448975, 0.7986224293708801, 0.8793811202049255, 0.5767821669578552, 0.44713565707206726, 0.47237613797187805, 0.3796745538711548, 0.49613577127456665, 0.34391942620277405, 0.26335957646369934, 0.17643456161022186, 0.20874810218811035, 0.2256513237953186, 0.23829391598701477, 0.20429956912994385, 0.1757480800151825, 0.21298344433307648, 0.196907177567482, 0.17291155457496643, 0.18902651965618134, 0.15019749104976654, 0.1832619607448578, 0.17820526659488678, 0.1645515114068985, 0.1403348743915558, 0.12373917549848557, 0.19563592970371246, 0.2048020362854004, 0.366242915391922, 0.1987697035074234, 0.18320992588996887, 0.14563320577144623, 0.16720929741859436, 0.20354047417640686, 0.35683876276016235, 0.15017956495285034, 0.16537150740623474, 0.13887955248355865, 0.18011462688446045, 0.12608851492404938, 0.1587345153093338, 0.11734865605831146, 0.09967485815286636, 0.2249457836151123, 0.1583428531885147, 0.1623801738023758, 0.1258806437253952, 0.18769195675849915, 0.13779231905937195, 0.08404829353094101, 0.08000121265649796, 0.07313595712184906, 0.07827404141426086, 0.07917948067188263, 0.056485798209905624, 0.03250683471560478, 0.04742817208170891, 0.0467158779501915, 0.0454876534640789, 0.02577408030629158, 0.034998539835214615, 0.03208654746413231, 0.01739821955561638, 0.033815328031778336, 0.015019104816019535, 0.013522731140255928, 0.014868192374706268, 0.013007700443267822, 0.012667016126215458, 0.02020246535539627, 0.009786355309188366, 0.013386236503720284, 0.009739524684846401, 0.006730220280587673, 0.005719562992453575, 0.008466523140668869, 0.005504637025296688, 0.009323814883828163, 0.0065057482570409775, 0.002927603432908654, 0.0070646111853420734, 0.01968611218035221, 0.003205991582944989, 0.0035484887193888426, 0.003843932878226042, 0.004053383134305477, 0.005500266328454018, 0.0027207673992961645, 0.0027833902277052402, 0.00231344741769135, 0.002270601922646165, 0.004033393692225218, 0.0019147854764014482, 0.002834032289683819, 0.0019404868362471461, 0.0028372872620821, 0.002828780561685562, 0.001796053838916123, 0.0016170021845027804] 
