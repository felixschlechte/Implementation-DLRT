Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja bis einschlie√ülich Epoche 50, dann nicht rangadaptiv 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.17 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.1256, 0.1135, 0.1135, 0.1135, 0.2097, 0.2999, 0.4667, 0.4958, 0.6083, 0.6869, 0.7969, 0.8637, 0.8724, 0.8934, 0.8941, 0.9025, 0.9119, 0.9031, 0.8842, 0.8555, 0.8908, 0.9007, 0.8944, 0.9117, 0.9186, 0.917, 0.9209, 0.9071, 0.9191, 0.9252, 0.9254, 0.9292, 0.9289, 0.9261, 0.8914, 0.9191, 0.9221, 0.9273, 0.9277, 0.9289, 0.9329, 0.9328, 0.8985, 0.9286, 0.9275, 0.9355, 0.9039, 0.9234, 0.9232, 0.9042, 0.8588, 0.9187, 0.9269, 0.9324, 0.9371, 0.9383, 0.9365, 0.9418, 0.9428, 0.943, 0.9443, 0.9457, 0.9462, 0.9475, 0.9469, 0.9468, 0.9475, 0.9481, 0.9483, 0.9493, 0.9493, 0.9512, 0.9511, 0.9513, 0.9511, 0.951, 0.9509, 0.9517, 0.9514, 0.953, 0.9521, 0.9506, 0.9525, 0.9534, 0.9514, 0.9525, 0.9527, 0.954, 0.9517, 0.9548, 0.9537, 0.9549, 0.9525, 0.9515, 0.9541, 0.9517, 0.9536, 0.9516, 0.9534, 0.954, 0.9577] 
Trainingsdauer: 832.6127519607544 
Rang Entwicklung Layer 1: [500, 30, 30, 30, 30, 27, 24, 21, 18, 15, 11, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] 
Rang Entwicklung Layer 2: [500, 30, 30, 30, 29, 27, 26, 24, 22, 20, 18, 16, 15, 15, 14, 13, 12, 12, 11, 10, 10, 10, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] 
Rang Entwicklung Layer 3: [500, 30, 30, 30, 30, 27, 26, 24, 22, 20, 18, 16, 15, 15, 14, 13, 13, 13, 12, 11, 10, 10, 10, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.301968574523926, 2.2988405227661133, 2.2958948612213135, 2.2537059783935547, 1.6613596677780151, 1.4152556657791138, 1.1931582689285278, 0.9731599688529968, 0.905913770198822, 0.791562020778656, 0.4867079257965088, 0.3929527699947357, 0.34028297662734985, 0.39981260895729065, 0.34611108899116516, 0.29784682393074036, 0.3856848478317261, 0.3538709282875061, 0.502017617225647, 0.3775215148925781, 0.34640440344810486, 0.40120965242385864, 0.29952093958854675, 0.2093486785888672, 0.25097954273223877, 0.20408374071121216, 0.25432583689689636, 0.27343249320983887, 0.19565777480602264, 0.21893569827079773, 0.20325054228305817, 0.14824619889259338, 0.2395341992378235, 0.37053975462913513, 0.2243638038635254, 0.2891554534435272, 0.21436698734760284, 0.25802773237228394, 0.22989369928836823, 0.24905164539813995, 0.2440928965806961, 0.34443262219429016, 0.18959994614124298, 0.21764251589775085, 0.18321934342384338, 0.3528345227241516, 0.2632823884487152, 0.2236124873161316, 0.36370396614074707, 0.4976136386394501, 0.33453428745269775, 0.1800467073917389, 0.20121514797210693, 0.15663479268550873, 0.18590021133422852, 0.15505480766296387, 0.18226923048496246, 0.1411331593990326, 0.1833387315273285, 0.10688269138336182, 0.14538609981536865, 0.12568780779838562, 0.1676657497882843, 0.13802509009838104, 0.13956110179424286, 0.14998164772987366, 0.16303963959217072, 0.1361437290906906, 0.1374385803937912, 0.13316746056079865, 0.1344299614429474, 0.18214847147464752, 0.15394511818885803, 0.09917513281106949, 0.1157103106379509, 0.17270305752754211, 0.131475567817688, 0.1373155266046524, 0.10900544375181198, 0.1362411081790924, 0.14286331832408905, 0.13466623425483704, 0.13944759964942932, 0.12423846870660782, 0.10883721709251404, 0.10624251514673233, 0.11564330756664276, 0.13279448449611664, 0.13915768265724182, 0.0838417336344719, 0.09565272927284241, 0.10055367648601532, 0.10152141004800797, 0.08150479942560196, 0.09478483349084854, 0.11017058044672012, 0.1479741632938385, 0.10095760971307755, 0.10683729499578476, 0.11909404397010803] 
