Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja au√üer letzte Layer 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.1 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.0938, 0.261, 0.3074, 0.4983, 0.6366, 0.7457, 0.7765, 0.8145, 0.8823, 0.8886, 0.9022, 0.9191, 0.9274, 0.927, 0.8674, 0.8775, 0.9021, 0.9184, 0.9239, 0.9291, 0.9305, 0.8813, 0.8966, 0.9206, 0.9291, 0.9297, 0.9326, 0.9371, 0.9414, 0.938, 0.9387, 0.9448, 0.9405, 0.9272, 0.9416, 0.9475, 0.9437, 0.9487, 0.9519, 0.9488, 0.9483, 0.9345, 0.9454, 0.9495, 0.9501, 0.9431, 0.9392, 0.8766, 0.9302, 0.9434, 0.9493, 0.9217, 0.9504, 0.9545, 0.9542, 0.9563, 0.9585, 0.9566, 0.9611, 0.961, 0.9612, 0.9597, 0.961, 0.9627, 0.9611, 0.961, 0.9653, 0.9597, 0.9625, 0.9647, 0.965, 0.9628, 0.9633, 0.9605, 0.9604, 0.9631, 0.9624, 0.9639, 0.9631, 0.9329, 0.9547, 0.9575, 0.9585, 0.9611, 0.9613, 0.9587, 0.9519, 0.9567, 0.9609, 0.9606, 0.9561, 0.9606, 0.9603, 0.9628, 0.962, 0.9607, 0.9603, 0.966, 0.9664, 0.9668, 0.9675] 
Trainingsdauer: 949.5867643356323 
Rang Entwicklung Layer 1: [500, 98, 76, 69, 63, 59, 56, 52, 50, 47, 45, 43, 42, 40, 39, 36, 34, 32, 31, 30, 30, 28, 24, 24, 23, 23, 23, 23, 22, 21, 20, 20, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18] 
Rang Entwicklung Layer 2: [500, 80, 74, 69, 65, 63, 60, 58, 57, 56, 55, 54, 53, 52, 51, 51, 49, 48, 47, 46, 45, 44, 42, 41, 40, 40, 39, 38, 38, 37, 37, 37, 36, 35, 35, 35, 35, 34, 34, 34, 33, 32, 32, 32, 32, 31, 31, 30, 30, 29, 29, 28, 28, 28, 27, 27, 27, 26, 26, 26, 26, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23] 
Rang Entwicklung Layer 3: [500, 79, 74, 70, 66, 64, 62, 60, 59, 57, 56, 55, 54, 53, 53, 53, 51, 51, 50, 49, 48, 48, 46, 45, 44, 44, 43, 42, 42, 41, 41, 41, 41, 40, 40, 39, 38, 38, 37, 37, 36, 36, 36, 36, 35, 35, 34, 34, 34, 34, 34, 33, 33, 32, 31, 31, 31, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28, 27, 27, 27, 26, 26, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 24] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.2811505794525146, 1.8948646783828735, 1.0882925987243652, 0.8988506197929382, 0.7193266749382019, 0.5632529854774475, 0.5182375311851501, 0.4187507629394531, 0.3044144809246063, 0.34088748693466187, 0.31276071071624756, 0.22242744266986847, 0.24959254264831543, 0.399466335773468, 0.5122479796409607, 0.29597488045692444, 0.2467854619026184, 0.2858908772468567, 0.17559118568897247, 0.2640324532985687, 0.487731009721756, 0.3085329234600067, 0.2922080159187317, 0.21269585192203522, 0.17451122403144836, 0.24413472414016724, 0.17441068589687347, 0.21485376358032227, 0.1822897493839264, 0.2269567847251892, 0.18336902558803558, 0.1441766917705536, 0.2885080575942993, 0.19791863858699799, 0.21689583361148834, 0.21926231682300568, 0.13444803655147552, 0.11596918851137161, 0.19291986525058746, 0.18186786770820618, 0.2177474945783615, 0.20353963971138, 0.15667487680912018, 0.14253468811511993, 0.15384437143802643, 0.16748084127902985, 0.48422881960868835, 0.2598629891872406, 0.17965666949748993, 0.1271275132894516, 0.3339412212371826, 0.11421254277229309, 0.11101898550987244, 0.1250464916229248, 0.11681632697582245, 0.14122886955738068, 0.08883413672447205, 0.09781527519226074, 0.09646890312433243, 0.08177658170461655, 0.08053197711706161, 0.1329188197851181, 0.06573882699012756, 0.12133067846298218, 0.10888544470071793, 0.10763654112815857, 0.06934373080730438, 0.0641440898180008, 0.07880928367376328, 0.0757417157292366, 0.08313748240470886, 0.07334475219249725, 0.07869910448789597, 0.10872180759906769, 0.0656849592924118, 0.07872585952281952, 0.07448296248912811, 0.08261192589998245, 0.24932563304901123, 0.12743309140205383, 0.08676359057426453, 0.08502303063869476, 0.07965048402547836, 0.09246784448623657, 0.055015455931425095, 0.1433810591697693, 0.13811030983924866, 0.0763060599565506, 0.09546802192926407, 0.15448512136936188, 0.11516065895557404, 0.0976487249135971, 0.06832060217857361, 0.12395468354225159, 0.08980973809957504, 0.1157955527305603, 0.07278094440698624, 0.04732997715473175, 0.10124366730451584, 0.05556367337703705] 
