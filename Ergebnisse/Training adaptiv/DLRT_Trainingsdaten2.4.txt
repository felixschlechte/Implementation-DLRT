Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja au√üer letzte Layer 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.1 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.0846, 0.1686, 0.3118, 0.554, 0.6812, 0.789, 0.8611, 0.8793, 0.8835, 0.8598, 0.9018, 0.8372, 0.8933, 0.8908, 0.9168, 0.9151, 0.9209, 0.9283, 0.9353, 0.9231, 0.7469, 0.8927, 0.9144, 0.9265, 0.9134, 0.9331, 0.9355, 0.9283, 0.9346, 0.9321, 0.9315, 0.9281, 0.9391, 0.9433, 0.9478, 0.9481, 0.9514, 0.9535, 0.9508, 0.9535, 0.9463, 0.9552, 0.9567, 0.9537, 0.9511, 0.9367, 0.9472, 0.9518, 0.9518, 0.9505, 0.9517, 0.9584, 0.9556, 0.9583, 0.9518, 0.9579, 0.9611, 0.9623, 0.6112, 0.9372, 0.949, 0.9495, 0.9578, 0.9587, 0.9621, 0.9556, 0.9524, 0.9564, 0.9598, 0.962, 0.9615, 0.9634, 0.9637, 0.9615, 0.9613, 0.9642, 0.9652, 0.9629, 0.9665, 0.9671, 0.9664, 0.9693, 0.9692, 0.97, 0.9708, 0.9715, 0.9716, 0.9717, 0.9253, 0.9591, 0.9634, 0.9659, 0.9654, 0.9656, 0.9667, 0.9694, 0.9695, 0.9693, 0.9691, 0.9698, 0.9731] 
Trainingsdauer: 938.4423294067383 
Rang Entwicklung Layer 1: [500, 99, 76, 70, 63, 58, 53, 50, 49, 45, 44, 41, 37, 36, 35, 33, 32, 32, 31, 30, 27, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21] 
Rang Entwicklung Layer 2: [500, 80, 73, 70, 65, 63, 60, 59, 58, 56, 55, 54, 52, 51, 50, 49, 49, 48, 47, 46, 45, 43, 42, 41, 40, 39, 39, 38, 38, 37, 36, 36, 35, 35, 35, 34, 34, 33, 33, 32, 32, 32, 31, 31, 30, 30, 30, 30, 29, 29, 29, 28, 28, 28, 28, 27, 27, 27, 27, 27, 26, 26, 26, 26, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 24, 24, 24, 24, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21] 
Rang Entwicklung Layer 3: [500, 80, 74, 70, 66, 64, 61, 59, 59, 57, 56, 55, 54, 53, 52, 52, 51, 50, 50, 50, 49, 47, 45, 44, 44, 43, 43, 42, 42, 41, 41, 40, 40, 39, 39, 38, 38, 38, 37, 37, 36, 36, 36, 35, 35, 35, 34, 34, 34, 34, 33, 33, 33, 33, 32, 32, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 29, 29, 29, 29, 29, 28, 28, 28, 28, 28, 28, 27, 27, 27, 26, 26, 26, 26, 26, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 24, 23, 23, 23, 23, 23] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.281796932220459, 1.862589955329895, 1.1710935831069946, 0.9279856085777283, 0.8053004145622253, 0.5748937726020813, 0.4239528179168701, 0.3651614487171173, 0.47237280011177063, 0.3545060455799103, 0.47838670015335083, 0.3915429413318634, 0.3453560769557953, 0.28103336691856384, 0.27914372086524963, 0.3060359060764313, 0.18207895755767822, 0.2581712603569031, 0.28153446316719055, 0.8471924066543579, 0.40586429834365845, 0.30641984939575195, 0.2535077631473541, 0.3138103783130646, 0.23349988460540771, 0.21746134757995605, 0.23811092972755432, 0.20995648205280304, 0.172577366232872, 0.2552470862865448, 0.23705972731113434, 0.22345395386219025, 0.15984956920146942, 0.14025360345840454, 0.1540137082338333, 0.13783736526966095, 0.12661167979240417, 0.11491643637418747, 0.108735591173172, 0.16552568972110748, 0.10666708648204803, 0.14462660253047943, 0.15038254857063293, 0.14893372356891632, 0.21988825500011444, 0.15515448153018951, 0.21429497003555298, 0.15718699991703033, 0.10688666999340057, 0.14858636260032654, 0.10603242367506027, 0.1651182323694229, 0.12005171179771423, 0.14670687913894653, 0.1566484123468399, 0.08201601356267929, 0.12132950872182846, 1.498705267906189, 0.18834497034549713, 0.08964432775974274, 0.13467809557914734, 0.11379499733448029, 0.09787441790103912, 0.10463874042034149, 0.13712218403816223, 0.09273381531238556, 0.11528030037879944, 0.0995405912399292, 0.08729448169469833, 0.14446116983890533, 0.12926672399044037, 0.10490427166223526, 0.10439528524875641, 0.11530490964651108, 0.11695072054862976, 0.12014568597078323, 0.08741819113492966, 0.08493532240390778, 0.09277518093585968, 0.07367872446775436, 0.09368539601564407, 0.07170651108026505, 0.09558233618736267, 0.07669062167406082, 0.03341888636350632, 0.061703428626060486, 0.08791305869817734, 0.2900330722332001, 0.09694603830575943, 0.09071128815412521, 0.1200796514749527, 0.11694294214248657, 0.08910106122493744, 0.10999711602926254, 0.07619687169790268, 0.06276877224445343, 0.0987611934542656, 0.062084898352622986, 0.0660591796040535, 0.051800183951854706] 
