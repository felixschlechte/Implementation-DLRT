Netz: 784 - 500 - 500 - 500 - 10 
Rang - adaptiv ?: ja au√üer letzte Layer 
Epochen: 100 
Euler - Schrittweite: 0.2 
SV Trunkierung: tau*norm(Sigma) mit tau = 0.1 
Batch - Size: 600 
Device: cuda 
______________________________________________________________ 
Accuracy: [0.1189, 0.168, 0.2614, 0.4444, 0.7354, 0.292, 0.8077, 0.7907, 0.7237, 0.8701, 0.8717, 0.8893, 0.9002, 0.8967, 0.8908, 0.9039, 0.9222, 0.9011, 0.8203, 0.9215, 0.9229, 0.9317, 0.9364, 0.9422, 0.9452, 0.948, 0.9453, 0.9489, 0.9431, 0.9503, 0.9533, 0.9559, 0.9568, 0.9567, 0.958, 0.9546, 0.9571, 0.9589, 0.9547, 0.9464, 0.9528, 0.9463, 0.954, 0.9583, 0.96, 0.9606, 0.9619, 0.9559, 0.9606, 0.9614, 0.9602, 0.9642, 0.9626, 0.9649, 0.9575, 0.9637, 0.9673, 0.9657, 0.966, 0.9683, 0.9679, 0.9676, 0.9682, 0.9655, 0.9644, 0.971, 0.9688, 0.9689, 0.9706, 0.9695, 0.9684, 0.9691, 0.9742, 0.9727, 0.972, 0.9722, 0.3082, 0.8842, 0.9407, 0.9378, 0.9505, 0.9419, 0.9458, 0.9486, 0.9582, 0.9617, 0.9604, 0.9541, 0.953, 0.9604, 0.9584, 0.9606, 0.9602, 0.9656, 0.9652, 0.9663, 0.6634, 0.9209, 0.9305, 0.9409, 0.9518] 
Trainingsdauer: 922.350626707077 
Rang Entwicklung Layer 1: [500, 98, 77, 72, 66, 58, 49, 45, 40, 38, 36, 35, 33, 31, 30, 28, 28, 27, 26, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 23, 23, 23, 23, 23, 23, 23, 22, 22, 21, 21, 21, 21, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18] 
Rang Entwicklung Layer 2: [500, 79, 74, 71, 67, 63, 57, 54, 51, 49, 48, 47, 45, 43, 43, 42, 41, 41, 40, 40, 39, 38, 38, 37, 36, 35, 35, 35, 34, 34, 33, 33, 33, 32, 32, 32, 32, 32, 32, 31, 31, 30, 30, 30, 30, 29, 29, 29, 29, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 26, 26, 26, 26, 25, 25, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24] 
Rang Entwicklung Layer 3: [500, 80, 74, 72, 68, 64, 60, 57, 55, 54, 52, 51, 50, 48, 47, 46, 45, 44, 44, 44, 43, 43, 42, 41, 41, 40, 39, 39, 39, 38, 38, 37, 37, 37, 36, 36, 36, 36, 35, 35, 35, 35, 35, 34, 34, 33, 33, 33, 33, 32, 32, 32, 32, 31, 31, 31, 30, 30, 30, 30, 29, 29, 29, 29, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 26, 25, 25, 24, 24, 24, 23, 23, 23, 23, 22, 22, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21] 
Rang Entwicklung Layer 4: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] 
Loss: [2.2823028564453125, 1.839996337890625, 1.4657628536224365, 0.8650328516960144, 2.1564271450042725, 0.6220169067382812, 0.7325950860977173, 0.6168209314346313, 0.4442097544670105, 0.4194716215133667, 0.39296019077301025, 0.3479805886745453, 0.3547619879245758, 0.312085896730423, 0.33872127532958984, 0.2243119329214096, 0.3309724032878876, 1.0946534872055054, 0.24961255490779877, 0.2662079632282257, 0.2348087877035141, 0.18245501816272736, 0.15188878774642944, 0.1889457404613495, 0.15280424058437347, 0.18524396419525146, 0.1739332526922226, 0.19114483892917633, 0.19137932360172272, 0.11918371915817261, 0.13459663093090057, 0.12298877537250519, 0.11033675819635391, 0.13624972105026245, 0.15967226028442383, 0.10760823637247086, 0.1043236181139946, 0.13296613097190857, 0.20118598639965057, 0.16385763883590698, 0.1523217111825943, 0.10503450781106949, 0.1134004071354866, 0.10541839897632599, 0.10458073019981384, 0.09024471044540405, 0.1415657252073288, 0.10490242391824722, 0.12362318485975266, 0.12909740209579468, 0.07853569090366364, 0.08661431074142456, 0.10311315208673477, 0.11630620062351227, 0.14351654052734375, 0.07469219714403152, 0.08451971411705017, 0.09146841615438461, 0.0650864765048027, 0.09055495262145996, 0.06362806260585785, 0.0696086660027504, 0.0881412997841835, 0.0871218889951706, 0.05764321610331535, 0.07971954345703125, 0.086600661277771, 0.08407184481620789, 0.08286957442760468, 0.07973188161849976, 0.05804413929581642, 0.09184934198856354, 0.09071527421474457, 0.04802531376481056, 0.07721325755119324, 2.3302652835845947, 0.3737485110759735, 0.16292811930179596, 0.19821561872959137, 0.1633899062871933, 0.16881892085075378, 0.13895586133003235, 0.18368662893772125, 0.1286908984184265, 0.07944384217262268, 0.11076480895280838, 0.13996101915836334, 0.14706920087337494, 0.12493673712015152, 0.10700751096010208, 0.10316694527864456, 0.1186530590057373, 0.0868053212761879, 0.10316070914268494, 0.09690044820308685, 0.36582493782043457, 0.23129747807979584, 0.20982182025909424, 0.19508130848407745, 0.16185496747493744] 
